{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "_Author: Dhavide Aruliah_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Assignment Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- [Question 1](#q-digit-plot)\n",
    "- [Question 2](#q-digit-counts)\n",
    "- [Question 3](#q-binarize)\n",
    "- [Question 4](#q-count-bin)\n",
    "- [Question 5](#q-dummy-conf)\n",
    "- [Question 6](#q-accuracy)\n",
    "- [Question 7](#q-linear)\n",
    "- [Question 8](#q-linear2)\n",
    "- [Question 9](#q-logreg)\n",
    "- [Question 10](#q-proba)\n",
    "- [Question 11](#q-logit)\n",
    "- [Question 12](#q-logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### EXPECTED TIME 1.5 HRS  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Activities in this Assignment\n",
    "\n",
    "This assignment provides an overview of *Classification* problems. You will use Scikit-Learn's implementation of Logistic Regression to evaluate a few approaches to classification using the [MNIST handwritten digit dataset](https://en.wikipedia.org/wiki/MNIST_database). Along the way, you'll get a chance to practice the skills you've developed for working with data using Numpy and Pandas to advantage.\n",
    "\n",
    "The primary goals are:\n",
    "+ to use the Scikit-Learn, Pandas, & Numpy APIs to formulate & solve classification problems\n",
    "+ to increase familiarity with confusion matrices & accuracy in the context of binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Examining the Digits data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Our standard data imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "Input data shape: (1797, 64)\tTarget data shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.DESCR)\n",
    "\n",
    "# Extract data and targets as Numpy arrays\n",
    "X_digits, y_digits = digits.data, digits.target\n",
    "print('Input data shape: {}\\tTarget data shape: {}'.format(X_digits.shape, y_digits.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To get a better feel of what the input data is, extract a row of 64 numbers, reshape it into an $8\\times8$ array, and examine the resulting matrix by printing the numeric values & by plotting it as an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  2. 12.  9.  0.  0.  0.]\n",
      " [ 0.  0. 11. 15. 12.  5.  0.  0.]\n",
      " [ 0.  0. 15.  5.  0. 14.  0.  0.]\n",
      " [ 0.  2. 15.  1.  0.  9.  7.  0.]\n",
      " [ 0.  4. 10.  0.  0.  7.  8.  0.]\n",
      " [ 0.  0. 12.  0.  0.  8. 10.  0.]\n",
      " [ 0.  2. 15.  5. 10. 16.  1.  0.]\n",
      " [ 0.  0.  5. 14. 12.  4.  0.  0.]]\n",
      "y_digits[130] = 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAABFhJREFUeJzt3TFrHWQYhuEvjUgoiAqCFKRTSYZMHTs46iA4OAgOGYqDDk5CQVqH9ie4qYNSKLg4iJOCiyAqha4RRLo4FDq4WEQR0uNPCA55m9xc1xzOc85w8y2Bd2uz2Syg6dyT/gLAyRE4hAkcwgQOYQKHMIFDmMAhTOAQJnAIe+okPvSVc28m/z1ue39vdO/Fzx6MbX3/y9xv23373thW2XePv9w67m+84BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAg7kdNFVX9/9M/o3vUL347uTTm8emVs6/nbP49tnUZecAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQ5XfQ/fLr7xejewc1rY1uTJ35u/HZnbOvj25fGtk4jLziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hZ/422fb+3uDaj4Nba73wzf2xraOxpbXe/+Gtsa2dW0+Pba211sVbP43uHccLDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmECh7Azf7ro0e5zY1tv3HtnbGuttV56eDi6N2Xn97lzQv8++3hs6zTygkOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCHszJ8uOv/V3bGtSx88M7a11loPRtfmTJ4T2rn4aGzrNPKCQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIezMny7a3t8b27p+4fOxrbXWOrh6bWzrr9f/HNu6f+WTsa3XLr86trXWWkeja8fzgkOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BB25m+THR3+OrZ1cHPuVthaa9348M7Y1td/XB7bevm9d8e2zj+8O7Z1GnnBIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgELa12Wye9HcATogXHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAj7D+wIRpoyCD1CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 130\n",
    "im = X_digits[k].reshape(8, 8)\n",
    "print(im)\n",
    "plt.imshow(im)\n",
    "plt.axis('off')\n",
    "print('y_digits[{}] = {}'.format(k, y_digits[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Apparently, row 130 of the matrix `X` (remember, indexed from zero, this is the 131st row from the top), when reshaped, yields the image above. The corresponding entry of the target vector `y` is $0$ which means that this image is intended to represent the numeral $0$. Whether this is obvious depends on the handwriting of the original author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-digit-plot\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 1\n",
    "\n",
    "Your task is extract the 1674th row from the matrix `X_digits` and determine which numeral that image corresponds to.\n",
    "\n",
    "+ Assign the row extracted to the identifier `ans_1_row`.\n",
    "+ Assign the associated digit (as an integer) to `ans_1_digit`.\n",
    "+ Remember, in extracting a row from `X_digits`, Python arrays use indexing from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1674th row corresponds to this image of the digit 6.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### GRADED\n",
    "### Plot the image from 1674th row of the matrix X_digits.\n",
    "### What numeral does this image represent? \n",
    "### Assign the row as ans_1_row and the associated digit (as an integer)\n",
    "### to the identifier ans_1_digit.\n",
    "## e.g., ans_1_digit = 9\n",
    "### YOUR SOLUTION HERE:\n",
    "ans_1_row = X_digits[1673]\n",
    "\n",
    "ans_1_digit = 6\n",
    "### For verifying answer:\n",
    "image_digit = ans_1_row.reshape(8, 8)\n",
    "print('The 1674th row corresponds to this image of the digit {}.'.format(ans_1_digit))\n",
    "plt.imshow(image_digit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 01",
     "locked": true,
     "points": "4",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Examining the Target Classes\n",
    "\n",
    "In classification problems, the labels (or targets) are *discrete* or *categorical* values (by contrast with regression problems). That being the case, it is generally preferable when the labelled data are *balanced*; that is, the labels are uniformly distributed in the training data from which models are built. For a binary classification problem (i.e., one with two classes), that means 50% of the data is from one class and 50% of the data from the other class. For a classification problem with $k$ classes, that would mean each class is represented in $(100 \\div k)$% of the data.\n",
    "\n",
    "Examining the target vector `y` for the MNIST Digits data, it appears that each numeral from the sequence $0$ through $9$ occurs in a random sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 9 5 5 6 5 0\n",
      " 9 8 9 8 4 1 7 7 3 5 1 0 0 2 2 7 8 2 0 1 2 6 3 3 7 3 3 4 6 6 6 4 9 1 5 0 9\n",
      " 5]\n",
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}\n"
     ]
    }
   ],
   "source": [
    "y = digits.target\n",
    "print(y[0:75])\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-digit-counts\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 2\n",
    "\n",
    "Your task here is to summarize how often each digit from $0$ through $9$ occurs in the vector `y_digits`.\n",
    "\n",
    "+ The result should be a Pandas Series with the integers $0$ though $9$ as the index (sorted in increasing order) and the corresponding counts as the data.\n",
    "+ HINT: the Pandas Series method `value_counts` can do this easily, as can the Numpy function `numpy.unique`.\n",
    "+ Assign the resulting Series to `ans_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw counts:\n",
      "===========\n",
      "3    183\n",
      "5    182\n",
      "1    182\n",
      "6    181\n",
      "4    181\n",
      "9    180\n",
      "7    179\n",
      "0    178\n",
      "2    177\n",
      "8    174\n",
      "dtype: int64\n",
      "\n",
      "Frequencies:\n",
      "============\n",
      "3    18.3\n",
      "5    18.2\n",
      "1    18.2\n",
      "6    18.1\n",
      "4    18.1\n",
      "9    18.0\n",
      "7    17.9\n",
      "0    17.8\n",
      "2    17.7\n",
      "8    17.4\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### Create a Pandas Series with a sorted index of the numerals 0 through 9. \n",
    "### The corresponding values are the counts of the occurrences of each digit\n",
    "### in the vector y_digits from the MNIST digits dataset.\n",
    "### Assign the result to the identifier ans_2.\n",
    "### YOUR SOLUTION HE\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "\n",
    "\n",
    "cts = pd.Series(y_digits)\n",
    "\n",
    "ans_2 = cts.value_counts()\n",
    "\n",
    "\n",
    "print('Raw counts:\\n===========\\n{}\\n'.format(ans_2))\n",
    "print('Frequencies:\\n============\\n{}\\n'.format(ans_2/len(ans_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 02",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Before proceeding with logistic regression, you will modify the problem to yield a *binary classification problem*. That is, rather than classifying images of the digits 0 through 9, you'll modify the category labels to $+1$ for the digit $9$ and $-1$ for everything else (the choice of labels is arbitrary; they are $+1$ and $-1$ in this case, but they could be, e.g., $+1$ and $0$).\n",
    "\n",
    "The preceding substitution yields a *two-class* or *binary classification problem* consistent with the discussion of logistic regression from the lectures. Of course, the problem will be quite unbalanced by virtue of the fact that only about 10% of the samples are images of the numeral $9$ and the remaining 90% correspond to other digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-binarize\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 3\n",
    "\n",
    "Your task here is to create a new array `ans_3_vec` in which $+1$ replaces $9$ in every occurrence in `y_digits`. All other entries (i.e., the digits $0$ through $8$) should be replaced by $-1$. This yields suitable targets for a binary classification problem.\n",
    "\n",
    "+ You will also create a Pandas Series (with a sorted index) that records the counts of each class (similar to Question 2).\n",
    "+ The result should be a Pandas Series with the integers $-1$ and $+1$ on the index (sorted in increasing order) and the corresponding counts as the data.\n",
    "+ Assign the Series of counts to `ans_3_counts`.\n",
    "+ HINT: the functions `numpy.where`, `numpy.unique`, and `pandas.Series.value_counts` may be useful for these tasks exactly as in earlier problems)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 10 entries of ans_3_vec: 1787   -1\n",
      "1788   -1\n",
      "1789   -1\n",
      "1790   -1\n",
      "1791   -1\n",
      "1792    1\n",
      "1793   -1\n",
      "1794   -1\n",
      "1795    1\n",
      "1796   -1\n",
      "dtype: int64\n",
      "\n",
      "Raw counts:\n",
      "===========\n",
      "-1    1617\n",
      " 1     180\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### Binarize the vector y_digits and count its various classes as described above.\n",
    "### Save the results as ans_3_vec & ans_3_counts.\n",
    "### YOUR SOLUTION HERE:\n",
    "cts = pd.Series(y_digits)\n",
    "#print(cts)\n",
    "s = cts.copy()\n",
    "t = s.where(s > 8, -1)\n",
    "u = t.where(s < 9, +1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ans_3_vec = u\n",
    "ans_3_counts = u.value_counts()\n",
    "### Verification:\n",
    "print('Last 10 entries of ans_3_vec: {}\\n'.format(ans_3_vec[-10:]))\n",
    "print('Raw counts:\\n===========\\n{}\\n'.format(ans_3_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 03",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_digits_bin = ans_3_vec # Preserve this answer for future computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Train/Test Split\n",
    "\n",
    "As usual, it's useful to divide the data into *training* and *testing* sets. The easiest way to do so is using the function `train_test_split` from the Scikit-Learn submodule `sklearn.model_selection` (you can consult the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to learn how to customize the behavior of this function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_digits_train, X_digits_test, y_digits_train, y_digits_test = \\\n",
    "         train_test_split(X_digits, y_digits_bin, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-count-bin\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 4\n",
    "\n",
    "Your task here is to create a Pandas DataFrame with the categories $-1$ and $+1$ in ascending order as the index and with two columns: `train` and `test`.\n",
    "+ The entries of each row, then, are the number of occurrences of each category in the training target `y_digits_train` and the testing target `y_digits_test` respectively.\n",
    "+ Bind the DataFrame to the identifier `ans_4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of each category:\n",
      "========================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1215</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train  test\n",
       "-1   1215   402\n",
       " 1    132    48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### GRADED\n",
    "### As in earlier questions, count the occurrences of each class,\n",
    "### but this time in the training & the testing data sets \n",
    "### (i.e., in y_digits_train and y_digits_test).\n",
    "### Assemble the results into a Pandas DataFrame with index\n",
    "### values -1 & +1 (sorted in ascending order) and with two\n",
    "### columns: train & test.\n",
    "### That is, your final DataFrame should have these headings:\n",
    "###        | train_counts | test_counts | \n",
    "### =======================================\n",
    "### Digits | \n",
    "### Assign the DataFrame to the identifier ans_4.\n",
    "\n",
    "a = pd.Series(y_digits_train)\n",
    "b = pd.Series(y_digits_test)\n",
    "#print(a,b)\n",
    "c = a.value_counts()\n",
    "d = b.value_counts()\n",
    "#print(c,d)\n",
    "sers = [c,d]\n",
    "f = pd.concat(sers)\n",
    "df = pd.DataFrame(f)\n",
    "df['train'] = df[0]\n",
    "df['test'] = df.iloc[[2,3], [0]]\n",
    "#df1 = \n",
    "\n",
    "#print(df1)\n",
    "\n",
    "\n",
    "\n",
    "ans_4 = df.iloc[:2,1:3]\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "print('Counts of each category:\\n'+ 24*'=')\n",
    "display(ans_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 04",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0.902004</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097996</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train      test\n",
       "-1  0.902004  0.893333\n",
       " 1  0.097996  0.106667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ans_4/ans_4.sum(axis=0)) # Display above solution as frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Using a Dummy Classifier\n",
    "\n",
    "As a first classifier, you can apply the built-in [`DummyClassifier` class from `sklearn.dummy`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) to set a baseline for performance of our future models.  This classifier does not actually use the feature matrix `X_digits_train`; classification decisions are made using the target vector `y_digits_train` only.  There are a few strategies, but we'll start with the `'most_frequent'` strategy.  That is, the `predict` method always returns the majority class. For our binary digit classification problem, this would be `-1` (because the `1` classification is reserved for `9`s and most of the digits are not `9`s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_digits_train, y_digits_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Having applied the `fit` method to the training data, you can use the `predict` method to see how this estimator classifies the data. Unsurprisingly, it returns a vector of all `-1`s (because that is the majority class for this data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "y_digits_pred = dummy.predict(X_digits_test)\n",
    "print(y_digits_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "You can find the fraction of correct classifications using the method `score` with the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correct classifications is: 0.893\n"
     ]
    }
   ],
   "source": [
    "score = dummy.score(X_digits_test, y_digits_test)\n",
    "print('The fraction of correct classifications is: {:5.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Using `dummy.score` is equivalent to explicitly comparing the entries of `y_digits_pred` to `y_digits_test`, counting the number of correct classifications, and dividing by the number of classifications in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correct classifications is: 0.893\n"
     ]
    }
   ],
   "source": [
    "# This is the long way of computing the accuracy score\n",
    "correct_classifications = (y_digits_pred == y_digits_test)\n",
    "score = correct_classifications.sum() / len(correct_classifications)\n",
    "print('The fraction of correct classifications is: {:5.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "For classification problems, a *confusion matrix* is a more detailed description of the accuracy of a classifier. It contains entries for the actual values as rows and predicted values as columns. This means we have:\n",
    "\n",
    "| $~$ | **predicted  (-1)** | **predicted (+1)** |\n",
    "| ---- | ----------- | ---------- |\n",
    "| **actual (-1)** |  true negative | false positive |\n",
    "| **actual (+1)** |  false negative | true positive |\n",
    "\n",
    "\n",
    "The preceding definition generalizes to the multi-class classification problems as well.\n",
    "In *Scikit-Learn*, the `confusion_matrix` function takes as arguments the actual labels followed by the predicted labels (labelled in ascending order according to the class labels). From the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html):\n",
    "\n",
    "> `sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)`\n",
    ">\n",
    "> Compute confusion matrix to evaluate the accuracy of a classification\n",
    ">\n",
    "> By definition a confusion matrix $C$ is such that $C_{i,j}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\n",
    ">\n",
    "> Thus in binary classification, the count of true negatives is $C_{0,0}$, false negatives is $C_{1,0}$, true positives is $C_{1,1}$, and false positives is $C_{0,1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-dummy-conf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 5\n",
    "\n",
    "Your task here is to generate the confusion matrix associated with the `DummyClassifier` just created and the test data for this digits binary classification problem (i.e., computing which images correspond to the digit `9` and which do not).\n",
    "+ The confusion matrix should be constructed as described above (i.e., consistent with the `sklearn` function `confusion_matrix`).\n",
    "+ You can construct the confusion matrix explicitly or you can use the function `confusion_matrix` from `sklearn.metrics` according to your preference.\n",
    "+ Save the 2D Numpy array for the confusion matrix to `ans_5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix:\n",
      "\n",
      "[[402   0]\n",
      " [ 48   0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### Use the DummyClassifier dummy (that was fit to the training data\n",
    "### (X_digits_train, y_digits_train) just above) to compute a confusion\n",
    "### matrix (as described above).\n",
    "### That is, use the prediction y_digits_pred generated above\n",
    "### & the test labels y_digits_test to build the corresponding confusion\n",
    "### matrix.\n",
    "### Assign the resulting 2D Numpy array to the identifier ans_5.\n",
    "### YOUR SOLUTION HERE:\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ans_5 = confusion_matrix(y_digits_test, y_digits_pred)\n",
    "### For verifying answer:\n",
    "print('Confusion_matrix:\\n\\n{}'.format(ans_5))\n",
    "print(type(ans_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 05",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Computing the Accuracy of a Binary Classifier\n",
    "\n",
    "The most basic way to assess performance is to compare the total number of correct predictions and the total number of observations.  This is the **accuracy**. Using the diagram of our confusion matrix above, the accuracy can be written as\n",
    "\n",
    "$$\\text{accuracy} = \\frac{\\mathtt{tp} + \\mathtt{tn}}{\\mathtt{tn} + \\mathtt{tp} + \\mathtt{fn} + \\mathtt{fp}}$$\n",
    "\n",
    "where $\\mathtt{tn}$, $\\mathtt{tp}$, $\\mathtt{fn}$, and $\\mathtt{fp}$ are the number of true negatives, true positives, false negatives, and false positives respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-accuracy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 6\n",
    "\n",
    "Your task here is to compose a function `accuracy_score` that implements the preceding formula. The input to the function is a (previously computed) confusion matrix and the output is an accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:  402\n",
      "TP:  0\n",
      "FN:  48\n",
      "FP:  0\n",
      "[[402   0]\n",
      " [ 48   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8933333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "### Complete the function accuracy_score below:\n",
    "###\n",
    "###\n",
    "\n",
    "def accuracy_score(confusion_matrix):\n",
    "    \n",
    "    TN = confusion_matrix.item(0)\n",
    "    print(\"TN: \",confusion_matrix.item(0))\n",
    "    \n",
    "    FP = confusion_matrix.item(1)\n",
    "    print(\"TP: \",confusion_matrix.item(1))\n",
    "    \n",
    "    FN = confusion_matrix.item(2)\n",
    "    print(\"FN: \",confusion_matrix.item(2))\n",
    "    \n",
    "    TP = confusion_matrix.item(3)\n",
    "    print(\"FP: \",confusion_matrix.item(3))\n",
    "    \n",
    "    print(ans_5)\n",
    "    \n",
    "    score = (TP + TN)/(TN + TP + FN + FP)\n",
    "    \n",
    "    return score\n",
    "    \n",
    "accuracy_score(ans_5)\n",
    "\n",
    "###\n",
    "### Insert your solution here:\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 06",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Using Linear Regression for Classification\n",
    "\n",
    "The `DummyClassifier` developed above gets about 90% accuracy without doing anything (simply because the training data is so unbalanced; this is a common scenario in binary classification problems). So any other classifier developed should at beat this.\n",
    "\n",
    "As seen in the lecture videos, you can try using a `LinearRegression` estimator and threshold the results to determine categories. The code below constructs the regression estimator, fits it to the training data, and makes a prediction based on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_lin = LinearRegression()\n",
    "model_lin.fit(X_digits_train, y_digits_train)\n",
    "y_digits_pred = model_lin.predict(X_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions in `y_digits_pred` are real numbers. For this binary classification problem, you need to *threshold* the values somehow to convert the labels to the categories $+1$ and $-1$. The threshold $t$ determines which category the predicted targets map to, i.e.,\n",
    "$$ y_k \\leftarrow \\text{threshold}(y_k, t) = \\begin{cases} +1, & y_{k}\\ge t \\\\ -1, & y_k<t \\end{cases}. $$\n",
    "The choice of threshold $t=0$ is consistent with the *sign* function (although any values between $-1$ and $+1$ would also be reasonable thresholds). The accuracy of the resulting classifier varies as the threshold changes (depending on the imbalance in the training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-linear\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 7\n",
    "\n",
    "You can now use the linear regression model just fit as a binary classifier.\n",
    "\n",
    "+ Apply a threshold of $t=0.0$ to the regression model's predictions `y_digits_pred` to yield a vector with $+1$ and $-1$ as entries; assign the vector to the identifier `ans_7a`.\n",
    "+ Use the thresholded binary vector `ans_7a` to compute a confusion matrix as in Question 5. Assign the $2\\times2$ confusion matrix to `ans_7b`.\n",
    "+ Use the confusion matrix just computed to compute the accuracy score (using your function from Question 6) for this classifier. Assign the accuracy computed to `ans_7c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "402\n",
      "0\n",
      "48\n",
      "Using Linear Regression with a threshold t=0.0:\n",
      "Confusion_matrix:\n",
      "\n",
      "[[398   4]\n",
      " [ 13  35]]\n",
      "\n",
      "Accuracy score: 0.893\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### Threshold the entries of y_digits_pred with the value t=0 to yield ans_7a.\n",
    "### Compute the corresponding confusion matrix & accuracy scores in ans_7b &\n",
    "###   ans_7c respectively.\n",
    "### YOUR SOLUTION HERE:\n",
    "\n",
    "ans_7a = np.where(y_digits_pred>=0,1,-1)\n",
    "ans_7b = confusion_matrix(y_digits_test, ans_7a, labels=None, sample_weight=None)\n",
    "ans_7c = accuracy_score(ans_7b)\n",
    "\n",
    "### For verifying answer:\n",
    "print('Using Linear Regression with a threshold t=0.0:')\n",
    "print('Confusion_matrix:\\n\\n{}\\n'.format(ans_7b))\n",
    "print('Accuracy score: {:5.3f}'.format(ans_7c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 07",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-linear2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 8\n",
    "\n",
    "This question is the same as Question 7, but using a different threshold $t=-0.1$\n",
    "\n",
    "+ Apply a threshold of $t=-0.1$ to the regression model's predictions `y_digits_pred` to yield a vector with $+1$ and $-1$ as entries; assign the vector to the identifier `ans_8a`.\n",
    "+ Use the thresholded binary vector `ans_8a` to compute a confusion matrix as in Question 5. Assign the $2\\times2$ confusion matrix to `ans_8b`.\n",
    "+ Use the confusion matrix just computed to compute the accuracy score (using your function from Question 6) for this classifier. Assign the accuracy computed to `ans_8c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "402\n",
      "0\n",
      "48\n",
      "Using Linear Regression with a threshold t=-0.1:\n",
      "Confusion_matrix:\n",
      "\n",
      "[[397   5]\n",
      " [  9  39]]\n",
      "\n",
      "Accuracy score: 0.893\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### Threshold the entries of y_digits_pred with the value t=-0.1 to yield ans_8a.\n",
    "### Compute the corresponding confusion matrix & accuracy scores in ans_8b &\n",
    "###   ans_8c respectively.\n",
    "### YOUR SOLUTION HERE:\n",
    "        \n",
    "ans_8a = np.where(y_digits_pred>=-0.1,1,-1)\n",
    "ans_8b = confusion_matrix(y_digits_test, ans_8a)\n",
    "ans_8c = accuracy_score(ans_8b)\n",
    "\n",
    "### For verifying answer:\n",
    "print('Using Linear Regression with a threshold t=-0.1:')\n",
    "print('Confusion_matrix:\\n\\n{}\\n'.format(ans_8b))\n",
    "print('Accuracy score: {:5.3f}'.format(ans_8c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 08",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression for Classification\n",
    "\n",
    "The `LinearRegression` classifier developed above gets about 96-97% accuracy depending on how the threshold is applied. Can Logistic Regression do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-logreg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 9\n",
    "\n",
    "Your task here is to instantiate and use a `LogisticRegression` estimator from `sklearn.linear_model` to work on the above binary classification problem.\n",
    "\n",
    "+ Instantiate a `LogisticRegression` estimator; assign the vector to the identifier `ans_9a`. Use the default constructor, i.e., don't worry about assigning other keyword arguments.\n",
    "+ Fit the instantiated `ans_9a` to the data `X_digits_train`.\n",
    "+ Use the estimator object `ans_9a` to predict the labels given the inputs in `X_digits_test`. Assign the result to `ans_9b`.\n",
    "+ Compute a confusion matrix and an accuracy score as in the preceding two questions. Assign the corresponding $2\\times2$ confusion matrix to `ans_9c` and the accuracy score to `ans_9d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "402\n",
      "0\n",
      "48\n",
      "Using Logistic Regression (default hyperparameters):\n",
      "Confusion_matrix:\n",
      "\n",
      "[[397   5]\n",
      " [  6  42]]\n",
      "\n",
      "Accuracy score: 0.893\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### Fit a LogisticRegression model, use it to predict labels from the test data\n",
    "###   & compute the corresponding confusion matrix and accuracy.\n",
    "### Use the identifiers ans_9a, ans_9b, ans_9c, & ans_9d for the LogisticRegression\n",
    "### object, the predicted labels, the confusion matrix, & the accuracy respectively.\n",
    "### YOUR SOLUTION HERE:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ans_9a = LogisticRegression()\n",
    "model_log = ans_9a.fit(X_digits_train, y_digits_train)\n",
    "ans_9b = ans_9a.predict(X_digits_test)\n",
    "ans_9c = confusion_matrix(y_digits_test, ans_9b)\n",
    "ans_9d = accuracy_score(ans_9c)\n",
    "\n",
    "\n",
    "### For verifying answer:\n",
    "print('Using Logistic Regression (default hyperparameters):')\n",
    "print('Confusion_matrix:\\n\\n{}\\n'.format(ans_9c))\n",
    "print('Accuracy score: {:5.3f}'.format(ans_9d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 09",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "You can bind the answers from Question 9 to more descriptive identifiers for the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_logreg = ans_9a\n",
    "y_logreg_pred = ans_9b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The `LogisticRegression` model just developed in `model_logreg` has a `coef_` attribute similar to that of the `LinearRegression` estimator. If you extract it, you can visualize the coefficients as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefs = model_logreg.coef_.reshape(8,8)\n",
    "plt.imshow(coefs)\n",
    "plt.colorbar()\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image above shows which pixels (features) in our model have the strongest effect in distinguishing the digit $9$ from the other digits. This can be useful in characterizing which features are most strongly correlated with producing accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-proba\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### Question 10\n",
    "\n",
    "Your task here is to use the `predict_proba` method of the object `model_logreg` to produce an array of probabilities associated with class labels for a few samples of the testing data.\n",
    "\n",
    "+ Given the subset `samples` of 5 rows from `X_digits_test`, apply `predict_proba` to determine the probabilities of assignment to each class.\n",
    "+ Assign the output returned from `predict_proba` to `ans_10a`.\n",
    "+ Use the 2D array of probabilities to determine the class labels associated with the rows from `samples`. Since the values in `ans_10a` are probabilities between 0 and 1, use the threshold of $0.5$ to determine whether to classify in class $+1$ or $-1$.\n",
    "+ Assign the resulting array of class labels to `ans_10b` (it should be a vector of length 5 with entries $+1$ or $-1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1 -1 -1]\n",
      "Results of predict_proba:\n",
      "[[9.99926166e-01 7.38342862e-05]\n",
      " [1.00000000e+00 3.21478775e-13]\n",
      " [7.50757547e-03 9.92492425e-01]\n",
      " [9.99997550e-01 2.45026284e-06]\n",
      " [9.99999999e-01 1.20705460e-09]]\n",
      "\n",
      "Resulting class labels:\n",
      "[[-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### Use predict_proba to determine an array of probabilities for the class labels\n",
    "###   for the array samples (samples is provided below). Save as ans_10a.\n",
    "### Use the result from ans_10a to compute the associated class labels with samples.\n",
    "###   Save as ans_10b.\n",
    "###\n",
    "samples = X_digits_test[50:55,:]\n",
    "### YOUR SOLUTION HERE:\n",
    "ans_10a = model_logreg.predict_proba(samples)\n",
    "ans_10b = np.where(ans_10a[:,1] >= 0.5,1,-1) #specifying the second column looks at +1 rather than the prob of 0 in the first\n",
    "print(ans_10b)\n",
    "print('Results of predict_proba:\\n{}\\n'.format(ans_10a))\n",
    "print('Resulting class labels:\\n{}'.format(ans_10b.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 10",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-logit\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 11\n",
    "\n",
    "Your penultimate task is to define a function `logit` to compute the *log-odds* (i.e., the logarithm of the odds) associated with a given probability $p$\n",
    "+ Provide your function definition in the cell below associated with the identifier `logit`.\n",
    "+ Recall the *logit* function can be defined mathematically as\n",
    "$$ \\text{logit}(p) = \\begin{cases}\n",
    "-\\infty, & p=0, \\\\\n",
    "\\log \\left(\\frac{p}{1-p}\\right), & 0<p<1,\\\\\n",
    "+\\infty, & p=1\n",
    "\\end{cases}.$$\n",
    "+ Have your function return `-np.inf` or `np.inf` when `p` is `0` or `1` respectively.\n",
    "+ Have your function return `np.nan` if $p<0$ or $p>1$.\n",
    "+ Be sure to use the *natural* logarithm (i.e., base $e$); this is implemented in Numpy with `numpy.log` (usually aliased as `np.log`).\n",
    "+ Be sure that the function is *vectorized*, i.e., that it can accept a Numpy array, a Pandas Series, or a Pandas DataFrame as input and still return the corresponding result with `logit` applied element-wise. HINT: the function `np.where` is very useful for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit(p) = \n",
      "[       -inf -2.19722458 -1.38629436  1.38629436  2.19722458         inf\n",
      "         nan]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "###\n",
    "### Complete the body of the function logit with the signature provided.\n",
    "### Be sure it agrees with the specifics described above.\n",
    "###\n",
    "### YOUR SOLUTION HERE:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def logit(p):\n",
    "    odds =(p/(1-p))\n",
    "    logit = np.log(odds)\n",
    "    return logit\n",
    "        \n",
    "### For verifying answer:\n",
    "p = np.array([0, 0.1, 0.2, 0.8, 0.9, 1, 5])\n",
    "print('logit(p) = \\n{}'.format(logit(p))) # Notice symmetry in values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        if (x==0):\n",
    "            return np.where(x==0,-np.inf, np.log(p/1-p))\n",
    "        elif (x==1):\n",
    "            return np.where(x==1,np.inf, np.log(p/1-p))\n",
    "        elif (x < 0):\n",
    "            return np.where(x<0, np.nan, np.log(p/1-p))\n",
    "        elif (x>1):\n",
    "            return np.where(x>1, np.nan, np.log(p/1-p))\n",
    "        else:\n",
    "        \n",
    "    list = []\n",
    "    for p_element in p:\n",
    "        if (p_element==0):\n",
    "            list.append(-np.inf)\n",
    "        elif (p_element==1):\n",
    "            list.append(np.inf)\n",
    "        elif (p_element<0) or (p_element>1):\n",
    "            list.append(np.nan)\n",
    "        elif (p_element>0) and (p_element<1):\n",
    "            list.append(np.where(p_element > 0, np.log(p/1-p), np.nan))\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 11",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "<a id=\"q-logistic\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "#### Question 12\n",
    "\n",
    "Your final task is to define a function `logistic` that implements the *logistic* function. Recall this function can be defined mathematically by the formula\n",
    "$\\displaystyle{\\text{logistic}(x) = \\frac{1}{1+e^{-x}}}$. This formula is algebraically equivalent to the formula $\\displaystyle{1 - \\frac{1}{1+e^{x}}}$. However, the former formula avoids overflow for large *positive* values of $x$ while the latter does the same for large *negative* values of $x$. That is, for large values, a piecewise-defined function along the lines of\n",
    "$$\n",
    "\\text{logistic}(x) = \\begin{cases}\n",
    "\\displaystyle{\\frac{1}{1+e^{-x}}}, & x \\ge 0 \\\\\n",
    "\\displaystyle{1 - \\frac{1}{1+e^{x}}}, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "is more robust for evaluating the logistic function for large (positive or negative) input values.\n",
    "\n",
    "+ Provide your function definition in the cell below associated with the identifier `logistic`.\n",
    "+ Use the piecewise strategy mentioned above to compute `logistic` which is more robust for large values. HINT: The function `np.where` is very useful for this.\n",
    "+ Have your function return `0` and `1` when the input is `-np.inf` and `+np.inf` respectively.\n",
    "+ Remember that $e^{x}$ is computed in Numpy by `np.exp(x)`. This is usually a more accurate way to evaluate the exponential function (i.e., avoid `np.e**x`).\n",
    "+ Be sure that the function is *vectorized*, i.e., that it can accept a Numpy array, a Pandas Series, or a Pandas DataFrame as input and still return the corresponding result with `logistic` applied element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic(x) = [0.  0.1 0.2 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "###\n",
    "### Complete the body of the function logistic with the signature provided.\n",
    "### Be sure it agrees with the specifics described above.\n",
    "###\n",
    "### YOUR SOLUTION HERE:\n",
    "def logistic(x):\n",
    "    return np.where(x >= 0, (1/(1+np.exp(-x))), (1-(1/(1+np.exp(x)))))\n",
    "    '''Computes logistic function, i.e., probability from log-odds\n",
    "    INPUT:\n",
    "    x : log-odds (arbitrary real values)\n",
    "    '''\n",
    "\n",
    "### For verifying answer:\n",
    "x = np.array([-np.inf,-2.19722458,-1.38629436,1.38629436,2.19722458,np.inf])\n",
    "print('logistic(x) = {}'.format(logistic(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 12",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": [],
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": [],
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
